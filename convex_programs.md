I wanted to list different types of convex programming sets.

At the most basic, is `Box`, where the only bounds are of the form `c_1 <= x_i <= c_2`; the set defined by the allowed `x_i` is then a product of intervals `[c_1,c_2]x[c_3,c_4]x...`.

Then there's `2VAR`, linear inequalities with two variables per clause. They take the form `a_i x_{i,1} + b_i x_{i,2} <= c_i`. Usually `2VAR` actually means the _integer_ solutions to this problem, where the coefficients are rational. This can be solved in pseudopolynomial time by the Hochbaum–Naor algorithm, so, a solution can be found efficiently if the integers in the solution are small. Unfortunately, the integers can actually be quite large, and is in fact NP-hard.

Then there's `LP`, the set of linear programs: `sum_i a_i x_i >= b`. Classically can be solved in polynomial time by interior point methods. Can ultimately approximate any convex set, but this may be extremely inefficient.

`QP` is "quadratic programming". It's usually described as an optimization program: optimize a (convex) quadratic objective, subject to `LP` constraints. In the thresholding sense whereby an optimization problem is turned into a feasibility problem, the set `QP` is quadratic sets defined by: (1) a bunch of linear constraints `sum_i a_i x_i >= b`, and (2) a single quadratic constraint `x^T Q x + a^T x + c <= t`, where `Q` is a PSD matrix, `a` is a vector, and `t` is a variable which _only_ occurs in that constraint (and not any of the linear ones). It includes all of LP.

(Convex) `QCQP` is "quadratically constrained quadratic programming". We are now allowed to have as many quadratic constraints like `x^T Q_i x + a_i^T x + c_i <= 0` as we'd like, as long as all the `Q_i`'s are PSD. It includes all of QP.

`SOCP` is "second-order cone programming", and is where we're allowed constraints of the form `||A x + b||_2 <= c x + d`. Here `A` is an `nxk` matrix, `b` is a length-`k` vector, `c` is a length `n` vector, and `d` is a constant. The `|| ... ||_2` is the standard vector 2-norm. This includes all of QCQP. SOCP is a good first example of _cone programming_: we're given the cone(s) `L_{n+1}` defined by `(x, t) st. ||x||_2 <= t` for each dimension `n`. Then we take LP's together with constraints of the form `(x_{i..j}, x_j) in L_{n+1}`, a cone membership constraint. This is enough to express all SOCP's. In general, if membership in a cone is easy to test, then any cone program can be solved in poylnomial time. This is sometimes called the [quadratic cone](https://docs.mosek.com/modeling-cookbook/cqo.html#sec-cqo-rquadcone).

`SDP` is where you have linear matrix inequalities, or equivalently, the PSD cone: `PSD_{n}` is the set of symmetric `nxn` matrices with only nonnegative eigenvalues. It includes all of SOCP. It is also the furthest we will go while still exploring only _semialgebraic_ constraints, see [wiki](https://en.wikipedia.org/wiki/Semialgebraic_set) for definition. Indeed, `SDP` is _almost_ exactly the same as the sets that are _convex and semialgebraic_, as proved [here](https://arxiv.org/abs/0709.4017), see further discussion [here](https://www.mit.edu/~parrilo/pubs/talkfiles/FoCM.pdf). There's some technical conditions on the boundary not being too flat.

The [power cone](https://docs.mosek.com/latest/toolbox/tutorial-ceo-shared.html) is defined by the three-variable power cone `P_α = { (x1,x2,x3) | 0 <= x1, 0 <= x2, x1^α * x2^(1-α) >= |x3| }`, for powers α (alpha) between 0 and 1. This is enough to build any kind of 'weighted' power cone, with `x1^p1 * x2^p2 * x3^p3 ... >= |xn|` with `sum_i p_i = 1`. It lets you arbitrary p-norms of vectors, include the 2-norm as a special case, and so it includes all of `SOCP`. It is _not_ semialgebraic, as we can have funny exponents like `P_{\sqrt{1/2}}` or `P_{\pi/4}`, and `x^0.7071..` is not algebraic. The convex sets defininable in the power cone I'm calling `POW`, since I can't otherwise find a name.

The [exponential cone](https://docs.mosek.com/modeling-cookbook/expo.html) is defined by `K_exp = { (x1,x2,x3) | 0 <= x1, 0 <= x2, x1 >= x2 * exp(x3/x2) }`. It's enough to get you logarithms, entropy, relative entropy, and more, so it is often called _relative entropy optimization_, or `REO`. As [this](https://people.lids.mit.edu/pari/REO.pdf) paper explains, `REO` includes all of `SOCP`. Interestingly, the exponential cone can be realized as an appropriate limit of the power cone as α goes to 1, as in section 4.1 of [this](https://people.lids.mit.edu/pari/REO.pdf) paper. It's similar to how the von Neumann entropy is the limit of the Renyi α-entropy as α goes to 1.

`GP`, for "geometric programming", is a funny case. It is defined in terms of [posynomials](https://optimization.cbe.cornell.edu/index.php?title=Geometric_programming) - a type of "**pos**itive pol**ynomial**"! Its sets are in general _not_ convex, but it can be reparameterized with `x_i = exp(y_i)` and then they can be solved with the exponential cone `REO`. This is the point discussed [here](https://docs.mosek.com/modeling-cookbook/expo.html#geometric-programming). `GP` includes all of `LP`, but in general is not semialgebraic.

Going beyond `REO`, [this](https://people.lids.mit.edu/pari/REO.pdf) paper discusses _quantum_ relative entropy, and there's a corresponding quantum power cone `QPOW` and quantum relative entropy cone `QREO`. These both require `SDP` to even build them, as they're only defined functions on PSD matrices. `QPOW` includes `SDP` and `POW`, and `QREO` includes `SDP` and `REO`.
