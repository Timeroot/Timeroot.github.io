Some people treat arXiv as a reliable source of good science before it becomes officially published. While it is true that many academics use it this way, it is important to understand that this is _because_ the people reading those papers already have a good sense of what is reasonable and trustworthy research, and what is not. Depending on the field, it may be much easier or harder to judge the validity of a result.

This page is where I've decided to collect some arxiv papers on complexity theory that are 'obviously' wrong - papers that claim to refute major open problems, without any apparent major new insights, usually in just a few pages. The purpose is to not to highlight people's errors (we all make them) but rather to build a case that arxiv should not be blindly trusted. For some of the papers below, I will comment on the main error. I might also include some funny quotes.

* [BQP is not in NP](https://arxiv.org/abs/2209.10398), 19 Sep 2022. Claims that there are problems in BQP but not in NP. The proof body is just over 1 page long. **Error**: The author relies on quantum circuits with uncomputable gate amplitudes. BQP can be equivalently defined with a variety of universal gate sets, but the gate amplitudes must all be computable. It is [well known](https://scottaaronson.blog/?p=2072) (ctrl+F for "uncomputable") since the 90's that uncomputable gates certainly put you outside of NP (and in fact outside of RE).

* [BQP = PSPACE](https://arxiv.org/abs/2301.10557), 24 Jan 2023. Claims that BQP can solve all of PSPACE. (That PSPACE can solve all of BQP is already known.) The algorithm is just under 1 page long. **Error**: Several confusions over whether different data is stored in different "registers" or different "leaves" (parts of state space). Also, a failure to uncompute: entangling operations in quantum computers generally require some kind of uncomputation to remove unwanted entanglement later. The uncomputation doubles the length of the circuit, and if this happens in a recursive algorithm of depth d this leads to 2^d blowup in circuit size. **Quote**:
 > There are many real-world applications of our result, such as playing games of strategy like chess or Go, or finding the shortest path without a map, or determining whether a regular expression generates every string over its alphabet.

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I don't think I agree that these would be the biggest "real-world applications" of an efficient way to solve all of PSPACE.

* [NP-hard problems are not in BQP](https://arxiv.org/abs/2311.05624), 10 Jul 2023. Claims to show that BQP does not contain NP. Proofs and definitions are roughly two pages. **Error**: Theorem 2. Makes the mistake that "for sufficiently large values of *t* this is hard" with "for all values of *t* this is hard". The absurd conclusion of what is written is that NP can solve undecidable problems. **Quote**:
 > As Oded Goldreich mentioned on his web page, one needs a novel insight to solve this problem. Someone anonymous said: “Experts agree that one cannot solve problems like P vs. NP with simple computability tricks.” This might be the reason why no one had tried it before.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This is a peculiar flavor of optimism (or is it pessimism?), to believe that a problem has stayed unsolved _because_ the experts don't try it _because_ they think it's hard -- rather than that experts _do_ try it, and fail, which is why they think it's hard!

* [Quantum and Probabilistic Computers Rigorously Powerful than Traditional Computers, and Derandomization](https://arxiv.org/abs/2308.09549), 21 Aug 2023. Claims that BPP is strictly bigger than P, i.e. derandomization is impossible. This is considered unlikely. In fact, claims the stronger statement that ZPP is strictly bigger than P (very unlikely), and uses the result to show that BQP is strictly bigger than P (very likely). **Error**: The biggest flag is Theorem 4.2: "The probabilistic Turing machine M0 constructed in proof of Theorem 4.1 runs in time O(n^k) for any k ∈ ℕ." By taking `k=1`, this would imply that the Turing machine runs in linear time -- and simulates every other polynomial time machine in the process! The mistake is that each polytime machine runs in O(n^k), but this k can vary from machine to machine, so you can't just take the union over all of them and get a fixed k. **Quote**:
 > Although [...] the conjecture that P = BPP, we are in doubt that this maybe not be the true case, because a proof of P = BPP does not exist.

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Indeed, not having a proof tends to be the case with conjectures.

* [Polynomial Time Algorithm for Boolean Satisfiability Problem](https://arxiv.org/pdf/2310.19833.pdf), 28 Oct 2023. Claims P=NP. I have not looked for the error because this one is actually quite long (and builds on several papges). Impressively, this comes with [an actual implementation](https://github.com/stmargaryan/sat_sol) of the SAT solver. I remain highly skeptical as our banking system has not collapsed.

* [A correspondence between the time and space complexity](https://arxiv.org/abs/2311.01184), 02 Nov 2023. Claims PSPACE=EXP. Actually mostly a reprinting of [an earlier attempt](https://scirate.com/arxiv/1907.04521) by the same author. Several works by the author on the topic have been published in journals. I'm not actually aware of any errors.

* [Proofs of Equalities NP = coNP = PSPACE: Simplification](https://arxiv.org/abs/2311.17939), 28 Nov 2023. The culmination of several works by the authors, e.g. (https://eudml.org/doc/296796)[this], which have been published. Claims what it says on the tin: NP=coNP=PSPACE. The proof proceeds by what claims to be a way to compress exponential-size proof trees (over polynomially many variables) into polynomial size. I'm not aware of any specific error.

* [On P Versus NP](https://arxiv.org/abs/2005.00809), 05 May 2020. Claims that P≠NP. Shares an author with the above one (that NP=PSPACE). This paper could have been much shorter, because the author's earlier work that NP=PSPACE immediately implies P≠NP!

* [P Versus NP](https://vixra.org/abs/2208.0167), 30 Aug 2022. Claims that P=NP. Not technically on arxiv, but here for honorable mention. The entire paper is less than one page. The errors here are actually kind of mathematically interesting:
  * The author is aware that Sudoku is NP-complete, but this is for a definition of sudoku that relies on allowing multiple solutions. They confuse this with the logic puzzler's definition of Sudoku, which usually requires a single unique solution. So if this was a correct algorithm, it would actually only be proving P=[UP](https://en.wikipedia.org/wiki/UP_(complexity)).
  * The proposed algorithm to solve Sudoku is an [arc consistency](https://en.wikipedia.org/wiki/AC-3_algorithm) algorithm: that every pair of local constraints is satisfiable, otherwise narrowing or fixing variables. This is indeed how most people solve Sudokus, with the [pencil marks](https://www.learn-sudoku.com/pencil-marks.html) approach to progressively eliminating possibilities. Sadly, this does not always solve Sudoku, even when it's guaranteed that there's a unique solution.
